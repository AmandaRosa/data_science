{
 "metadata": {
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8  ('spyder-env': conda)"
  },
  "interpreter": {
   "hash": "43496aba4c2f39dc70f731bbf79c9e9f4191940c577d321f2d1de3240b56bdf5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import numpy as np\n",
    "from data_science import CompareData\n",
    "from data_science.tools import CompressWavelet"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from data_science.analysis_methodology import (\n",
    "    Autoencoder,\n",
    "    ClusterAnalysisDivergence,\n",
    "    DeepAnT_CNN,\n",
    "    HistogramConsistencyTest,\n",
    "    ProcessingArchitecture,\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# load data (download https://1drv.ms/u/s!AuAnQXzLmsvjihFVtI28bX0y0OyW?e=dDug9Y)\n",
    "abs_path = os.path.dirname(os.getcwd()) + \"/examples\"\n",
    "data = np.load(abs_path + \"/data/data_3.npy\")\n",
    "# get dt\n",
    "fs = 10000\n",
    "dt = 1 / fs\n",
    "#remove time column\n",
    "data = data[: fs * 6, :4]"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "histogram = HistogramConsistencyTest(\n",
    "    nominal_rotation=60, filter_type=\"frequency\", p_value_limit=0.05\n",
    ")\n",
    "\n",
    "auto_encoder = Autoencoder(size_sub_pack=512,)\n",
    "\n",
    "deep_ant = DeepAnT_CNN(epochs=2)\n",
    "\n",
    "adaptative_cluster = ClusterAnalysisDivergence(\n",
    "    n_channels=True,\n",
    "    size_sub_sample=256,\n",
    "    oversampling=True,\n",
    "    step_to_overlaps=50,\n",
    "    discriminators=[\"rms\", \"kurtosis\", \"peak value\"],\n",
    "    nb_cluster=6,\n",
    "    threshold=None,\n",
    "    sigma=2.5,\n",
    "    size_buffer=8,\n",
    ")\n",
    "\n",
    "processing_architecture = ProcessingArchitecture(\n",
    "    [auto_encoder, deep_ant, histogram, adaptative_cluster,]\n",
    ")\n",
    "\n",
    "# # start comparison\n",
    "\n",
    "compare_test = CompareData(data, dt, processing_architecture, slice_size=4000)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of samples: 15\n",
      "0 of 15 samples analyzed...\n",
      "Iniciando an√°lise da amostra\n",
      "==================================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, None, 24)          216       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 24)          1176      \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, None, 24)          1176      \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, None, 24)          1176      \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, None, 24)          1176      \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, None, 24)          1176      \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, None, 24)          1176      \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, None, 24)          1176      \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, None, 4)           100       \n",
      "=================================================================\n",
      "Total params: 8,548\n",
      "Trainable params: 8,548\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "================================\n",
      "Training with the 1th signal.\n",
      "Epoch 1/1000\n",
      "9/9 [==============================] - 3s 205ms/step - loss: 0.4772 - val_loss: 0.4243\n",
      "Epoch 2/1000\n",
      "9/9 [==============================] - 1s 151ms/step - loss: 0.4027 - val_loss: 0.3380\n",
      "Epoch 3/1000\n",
      "9/9 [==============================] - 1s 139ms/step - loss: 0.3264 - val_loss: 0.2846\n",
      "Epoch 4/1000\n",
      "9/9 [==============================] - 1s 148ms/step - loss: 0.2744 - val_loss: 0.2447\n",
      "Epoch 5/1000\n",
      "9/9 [==============================] - 1s 150ms/step - loss: 0.2359 - val_loss: 0.2000\n",
      "Epoch 6/1000\n",
      "9/9 [==============================] - 1s 157ms/step - loss: 0.1843 - val_loss: 0.1200\n",
      "Epoch 7/1000\n",
      "9/9 [==============================] - 1s 109ms/step - loss: 0.1024 - val_loss: 0.0680\n",
      "Epoch 8/1000\n",
      "9/9 [==============================] - 1s 132ms/step - loss: 0.0584 - val_loss: 0.0364\n",
      "Epoch 9/1000\n",
      "9/9 [==============================] - 1s 72ms/step - loss: 0.0334 - val_loss: 0.0257\n",
      "Epoch 10/1000\n",
      "9/9 [==============================] - 1s 118ms/step - loss: 0.0256 - val_loss: 0.0232\n",
      "Epoch 11/1000\n",
      "9/9 [==============================] - 1s 77ms/step - loss: 0.0227 - val_loss: 0.0204\n",
      "Epoch 12/1000\n",
      "9/9 [==============================] - 1s 128ms/step - loss: 0.0207 - val_loss: 0.0193\n",
      "Epoch 13/1000\n",
      "9/9 [==============================] - 1s 128ms/step - loss: 0.0201 - val_loss: 0.0184\n",
      "Epoch 14/1000\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 0.0189 - val_loss: 0.0176\n",
      "Epoch 15/1000\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.0183 - val_loss: 0.0179\n",
      "Epoch 16/1000\n",
      "9/9 [==============================] - 1s 109ms/step - loss: 0.0184 - val_loss: 0.0174\n",
      "Epoch 17/1000\n",
      "9/9 [==============================] - 1s 141ms/step - loss: 0.0173 - val_loss: 0.0164\n",
      "Epoch 18/1000\n",
      "9/9 [==============================] - 1s 111ms/step - loss: 0.0167 - val_loss: 0.0160\n",
      "Epoch 19/1000\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.0162 - val_loss: 0.0160\n",
      "Epoch 20/1000\n",
      "9/9 [==============================] - 1s 131ms/step - loss: 0.0160 - val_loss: 0.0153\n",
      "Epoch 21/1000\n",
      "9/9 [==============================] - 1s 141ms/step - loss: 0.0155 - val_loss: 0.0149\n",
      "Epoch 22/1000\n",
      "9/9 [==============================] - 1s 124ms/step - loss: 0.0150 - val_loss: 0.0151\n",
      "Epoch 23/1000\n",
      "9/9 [==============================] - 1s 117ms/step - loss: 0.0150 - val_loss: 0.0140\n",
      "Epoch 24/1000\n",
      "9/9 [==============================] - 1s 80ms/step - loss: 0.0145 - val_loss: 0.0143\n",
      "Epoch 25/1000\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.0143 - val_loss: 0.0139\n",
      "Epoch 26/1000\n",
      "9/9 [==============================] - 1s 130ms/step - loss: 0.0142 - val_loss: 0.0138\n",
      "Epoch 27/1000\n",
      "9/9 [==============================] - 1s 121ms/step - loss: 0.0141 - val_loss: 0.0139\n",
      "Epoch 28/1000\n",
      "9/9 [==============================] - 1s 137ms/step - loss: 0.0137 - val_loss: 0.0131\n",
      "Epoch 29/1000\n",
      "9/9 [==============================] - 1s 134ms/step - loss: 0.0135 - val_loss: 0.0133\n",
      "Epoch 30/1000\n",
      "9/9 [==============================] - 2s 169ms/step - loss: 0.0137 - val_loss: 0.0130\n",
      "Epoch 31/1000\n",
      "9/9 [==============================] - 2s 173ms/step - loss: 0.0132 - val_loss: 0.0131\n",
      "Epoch 32/1000\n",
      "9/9 [==============================] - 2s 210ms/step - loss: 0.0135 - val_loss: 0.0128\n",
      "Epoch 33/1000\n",
      "9/9 [==============================] - 2s 207ms/step - loss: 0.0130 - val_loss: 0.0126\n",
      "Epoch 34/1000\n",
      "9/9 [==============================] - 2s 252ms/step - loss: 0.0130 - val_loss: 0.0122\n",
      "Epoch 35/1000\n",
      "9/9 [==============================] - 2s 170ms/step - loss: 0.0128 - val_loss: 0.0126\n",
      "Epoch 36/1000\n",
      "9/9 [==============================] - 1s 138ms/step - loss: 0.0126 - val_loss: 0.0121\n",
      "Epoch 37/1000\n",
      "9/9 [==============================] - 2s 219ms/step - loss: 0.0124 - val_loss: 0.0121\n",
      "Epoch 38/1000\n",
      "9/9 [==============================] - 1s 130ms/step - loss: 0.0123 - val_loss: 0.0120\n",
      "Epoch 39/1000\n",
      "9/9 [==============================] - 1s 126ms/step - loss: 0.0124 - val_loss: 0.0121\n",
      "Epoch 40/1000\n",
      "9/9 [==============================] - 1s 151ms/step - loss: 0.0125 - val_loss: 0.0117\n",
      "Epoch 41/1000\n",
      "9/9 [==============================] - 2s 217ms/step - loss: 0.0120 - val_loss: 0.0126\n",
      "Epoch 42/1000\n",
      "9/9 [==============================] - 2s 239ms/step - loss: 0.0122 - val_loss: 0.0118\n",
      "Epoch 43/1000\n",
      "9/9 [==============================] - 2s 184ms/step - loss: 0.0120 - val_loss: 0.0116\n",
      "Epoch 44/1000\n",
      "9/9 [==============================] - 1s 116ms/step - loss: 0.0120 - val_loss: 0.0117\n",
      "Epoch 45/1000\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.0122 - val_loss: 0.0121\n",
      "Epoch 46/1000\n",
      "9/9 [==============================] - 1s 155ms/step - loss: 0.0121 - val_loss: 0.0116\n",
      "Epoch 47/1000\n",
      "9/9 [==============================] - 1s 81ms/step - loss: 0.0116 - val_loss: 0.0114\n",
      "Epoch 48/1000\n",
      "9/9 [==============================] - 1s 110ms/step - loss: 0.0118 - val_loss: 0.0112\n",
      "auto encoder: 62823.45 ms\n",
      "deep ant: 1.31 ms\n",
      "histogram: --\n",
      "clustering: --\n",
      "TOTAL: 62825.21 ms \n",
      "\n",
      "Iniciando an√°lise da amostra\n",
      "==================================================\n",
      "================================\n",
      "Training with the 2th signal.\n",
      "Epoch 49/1000\n",
      "9/9 [==============================] - 1s 160ms/step - loss: 0.0147 - val_loss: 0.0139\n",
      "Epoch 50/1000\n",
      "9/9 [==============================] - 1s 159ms/step - loss: 0.0136 - val_loss: 0.0138\n",
      "Epoch 51/1000\n",
      "9/9 [==============================] - 1s 110ms/step - loss: 0.0132 - val_loss: 0.0126\n",
      "Epoch 52/1000\n",
      "9/9 [==============================] - 1s 158ms/step - loss: 0.0128 - val_loss: 0.0120\n",
      "Epoch 53/1000\n",
      "9/9 [==============================] - 1s 101ms/step - loss: 0.0125 - val_loss: 0.0117\n",
      "Epoch 54/1000\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 0.0123 - val_loss: 0.0117\n",
      "Epoch 55/1000\n",
      "9/9 [==============================] - 1s 151ms/step - loss: 0.0122 - val_loss: 0.0121\n",
      "Epoch 56/1000\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.0126 - val_loss: 0.0119\n",
      "Epoch 57/1000\n",
      "9/9 [==============================] - 1s 125ms/step - loss: 0.0124 - val_loss: 0.0119\n",
      "Epoch 58/1000\n",
      "9/9 [==============================] - 1s 77ms/step - loss: 0.0126 - val_loss: 0.0115\n",
      "Epoch 59/1000\n",
      "9/9 [==============================] - 1s 126ms/step - loss: 0.0121 - val_loss: 0.0125\n",
      "Epoch 60/1000\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.0123 - val_loss: 0.0116\n",
      "Epoch 61/1000\n",
      "9/9 [==============================] - 1s 119ms/step - loss: 0.0122 - val_loss: 0.0117\n",
      "Epoch 62/1000\n",
      "9/9 [==============================] - 1s 113ms/step - loss: 0.0120 - val_loss: 0.0115\n",
      "Epoch 63/1000\n",
      "9/9 [==============================] - 1s 97ms/step - loss: 0.0122 - val_loss: 0.0116\n",
      "Epoch 64/1000\n",
      "9/9 [==============================] - 1s 105ms/step - loss: 0.0121 - val_loss: 0.0114\n",
      "Epoch 65/1000\n",
      "9/9 [==============================] - 1s 107ms/step - loss: 0.0122 - val_loss: 0.0115\n",
      "Epoch 66/1000\n",
      "9/9 [==============================] - 1s 120ms/step - loss: 0.0122 - val_loss: 0.0116\n",
      "Epoch 67/1000\n",
      "9/9 [==============================] - 1s 118ms/step - loss: 0.0121 - val_loss: 0.0113\n",
      "Epoch 68/1000\n",
      "9/9 [==============================] - 1s 131ms/step - loss: 0.0118 - val_loss: 0.0116\n",
      "auto encoder: 22038.18 ms\n",
      "deep ant: 0.91 ms\n",
      "histogram: --\n",
      "clustering: --\n",
      "TOTAL: 22039.24 ms \n",
      "\n",
      "Iniciando an√°lise da amostra\n",
      "==================================================\n",
      "================================\n",
      "Training with the 3th signal.\n",
      "Epoch 69/1000\n",
      "9/9 [==============================] - 1s 109ms/step - loss: 0.0196 - val_loss: 0.0167\n",
      "Epoch 70/1000\n",
      "9/9 [==============================] - 1s 130ms/step - loss: 0.0157 - val_loss: 0.0143\n",
      "Epoch 71/1000\n",
      "9/9 [==============================] - 1s 143ms/step - loss: 0.0139 - val_loss: 0.0117\n",
      "Epoch 72/1000\n",
      "9/9 [==============================] - 1s 165ms/step - loss: 0.0130 - val_loss: 0.0132\n",
      "Epoch 73/1000\n",
      "9/9 [==============================] - 1s 142ms/step - loss: 0.0123 - val_loss: 0.0117\n",
      "Epoch 74/1000\n",
      "9/9 [==============================] - 1s 139ms/step - loss: 0.0119 - val_loss: 0.0115\n",
      "Epoch 75/1000\n",
      "9/9 [==============================] - 1s 104ms/step - loss: 0.0117 - val_loss: 0.0111\n",
      "Epoch 76/1000\n",
      "9/9 [==============================] - 1s 133ms/step - loss: 0.0115 - val_loss: 0.0110\n",
      "Epoch 77/1000\n",
      "9/9 [==============================] - 1s 105ms/step - loss: 0.0115 - val_loss: 0.0110\n",
      "Epoch 78/1000\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 0.0114 - val_loss: 0.0110\n",
      "Epoch 79/1000\n",
      "9/9 [==============================] - 1s 125ms/step - loss: 0.0114 - val_loss: 0.0110\n",
      "Epoch 80/1000\n",
      "9/9 [==============================] - 1s 139ms/step - loss: 0.0113 - val_loss: 0.0109\n",
      "Epoch 81/1000\n",
      "9/9 [==============================] - 2s 193ms/step - loss: 0.0113 - val_loss: 0.0109\n",
      "auto encoder: 16006.76 ms\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_9 (Conv1D)            (None, 3999, 32)          96        \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 1999, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 1998, 32)          2080      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 999, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 31968)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 40)                1278760   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2000)              82000     \n",
      "=================================================================\n",
      "Total params: 1,362,936\n",
      "Trainable params: 1,362,936\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "deep ant: 1171.68 ms\n",
      "histogram: --\n",
      "clustering: --\n",
      "TOTAL: 17178.87 ms \n",
      "\n",
      "Iniciando an√°lise da amostra\n",
      "==================================================\n",
      "================================\n",
      "Training with the 4th signal.\n",
      "Epoch 82/1000\n",
      "9/9 [==============================] - 1s 154ms/step - loss: 0.0184 - val_loss: 0.0158\n",
      "Epoch 83/1000\n",
      "9/9 [==============================] - 2s 172ms/step - loss: 0.0152 - val_loss: 0.0124\n",
      "Epoch 84/1000\n",
      "9/9 [==============================] - 2s 169ms/step - loss: 0.0131 - val_loss: 0.0114\n",
      "Epoch 85/1000\n",
      "9/9 [==============================] - 2s 191ms/step - loss: 0.0122 - val_loss: 0.0110\n",
      "Epoch 86/1000\n",
      "9/9 [==============================] - 2s 195ms/step - loss: 0.0119 - val_loss: 0.0107\n",
      "Epoch 87/1000\n",
      "9/9 [==============================] - 2s 217ms/step - loss: 0.0117 - val_loss: 0.0108\n",
      "Epoch 88/1000\n",
      "9/9 [==============================] - 2s 190ms/step - loss: 0.0117 - val_loss: 0.0107\n",
      "Epoch 89/1000\n",
      "9/9 [==============================] - 1s 135ms/step - loss: 0.0116 - val_loss: 0.0108\n",
      "Epoch 90/1000\n",
      "9/9 [==============================] - 1s 116ms/step - loss: 0.0115 - val_loss: 0.0109\n",
      "Epoch 91/1000\n",
      "9/9 [==============================] - 2s 192ms/step - loss: 0.0116 - val_loss: 0.0104\n",
      "Epoch 92/1000\n",
      "9/9 [==============================] - 2s 196ms/step - loss: 0.0116 - val_loss: 0.0104\n",
      "Epoch 93/1000\n",
      "9/9 [==============================] - 1s 158ms/step - loss: 0.0114 - val_loss: 0.0106\n",
      "Epoch 94/1000\n",
      "9/9 [==============================] - 2s 215ms/step - loss: 0.0115 - val_loss: 0.0112\n",
      "Epoch 95/1000\n",
      "9/9 [==============================] - 1s 96ms/step - loss: 0.0115 - val_loss: 0.0106\n",
      "auto encoder: 21738.53 ms\n",
      "deep ant: 418.77 ms\n",
      "histogram: 29.62 ms\n",
      "clustering: 470.62 ms\n",
      "TOTAL: 22658.25 ms \n",
      "\n",
      "Iniciando an√°lise da amostra\n",
      "==================================================\n",
      "================================\n",
      "Training with the 5th signal.\n",
      "Epoch 96/1000\n",
      "9/9 [==============================] - 1s 139ms/step - loss: 0.0134 - val_loss: 0.0114\n",
      "Epoch 97/1000\n",
      "9/9 [==============================] - 1s 86ms/step - loss: 0.0123 - val_loss: 0.0110\n",
      "Epoch 98/1000\n",
      "9/9 [==============================] - 1s 85ms/step - loss: 0.0118 - val_loss: 0.0106\n",
      "Epoch 99/1000\n",
      "9/9 [==============================] - 1s 159ms/step - loss: 0.0116 - val_loss: 0.0109\n",
      "Epoch 100/1000\n",
      "9/9 [==============================] - 1s 152ms/step - loss: 0.0115 - val_loss: 0.0105\n",
      "Epoch 101/1000\n",
      "9/9 [==============================] - 1s 108ms/step - loss: 0.0114 - val_loss: 0.0106\n",
      "Epoch 102/1000\n",
      "9/9 [==============================] - 2s 192ms/step - loss: 0.0116 - val_loss: 0.0104\n",
      "Epoch 103/1000\n",
      "9/9 [==============================] - 1s 135ms/step - loss: 0.0114 - val_loss: 0.0109\n",
      "Epoch 104/1000\n",
      "9/9 [==============================] - 1s 133ms/step - loss: 0.0117 - val_loss: 0.0107\n",
      "Epoch 105/1000\n",
      "9/9 [==============================] - 2s 172ms/step - loss: 0.0116 - val_loss: 0.0105\n",
      "Epoch 106/1000\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 0.0114 - val_loss: 0.0105\n",
      "auto encoder: 13836.34 ms\n",
      "deep ant: 375.07 ms\n",
      "histogram: 29.73 ms\n",
      "clustering: 420.66 ms\n",
      "TOTAL: 14663.40 ms \n",
      "\n",
      "Iniciando an√°lise da amostra\n",
      "==================================================\n",
      "================================\n",
      "Training with the 6th signal.\n",
      "Epoch 107/1000\n",
      "9/9 [==============================] - 1s 79ms/step - loss: 0.0171 - val_loss: 0.0144\n",
      "Epoch 108/1000\n",
      "9/9 [==============================] - 1s 85ms/step - loss: 0.0145 - val_loss: 0.0117\n",
      "Epoch 109/1000\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.0131 - val_loss: 0.0118\n",
      "Epoch 110/1000\n",
      "9/9 [==============================] - 1s 109ms/step - loss: 0.0128 - val_loss: 0.0105\n",
      "Epoch 111/1000\n",
      "9/9 [==============================] - 1s 124ms/step - loss: 0.0125 - val_loss: 0.0101\n",
      "Epoch 112/1000\n",
      "9/9 [==============================] - 1s 107ms/step - loss: 0.0122 - val_loss: 0.0105\n",
      "Epoch 113/1000\n",
      "9/9 [==============================] - 1s 84ms/step - loss: 0.0121 - val_loss: 0.0101\n",
      "Epoch 114/1000\n",
      "9/9 [==============================] - 1s 138ms/step - loss: 0.0120 - val_loss: 0.0104\n",
      "Epoch 115/1000\n",
      "9/9 [==============================] - 1s 131ms/step - loss: 0.0120 - val_loss: 0.0102\n",
      "Epoch 116/1000\n",
      "9/9 [==============================] - 2s 166ms/step - loss: 0.0120 - val_loss: 0.0101\n",
      "Epoch 117/1000\n",
      "9/9 [==============================] - 1s 133ms/step - loss: 0.0120 - val_loss: 0.0104\n",
      "Epoch 118/1000\n",
      "9/9 [==============================] - 1s 107ms/step - loss: 0.0120 - val_loss: 0.0106\n",
      "Epoch 119/1000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.0121 - val_loss: 0.0105\n",
      "Epoch 120/1000\n",
      "9/9 [==============================] - 1s 77ms/step - loss: 0.0120 - val_loss: 0.0103\n",
      "================================\n",
      "Training ended at the 6th signal.\n",
      "MAE val = 0.010253150947391987\n",
      "================================\n",
      "auto encoder: 13160.13 ms\n",
      "deep ant: 359.06 ms\n",
      "histogram: 46.37 ms\n",
      "clustering: 476.32 ms\n",
      "TOTAL: 14044.07 ms \n",
      "\n",
      "Iniciando an√°lise da amostra\n",
      "==================================================\n",
      "auto encoder: 311.02 ms\n",
      "deep ant: 480.30 ms\n",
      "histogram: --\n",
      "clustering: --\n",
      "TOTAL: 792.03 ms \n",
      "\n",
      "Iniciando an√°lise da amostra\n",
      "==================================================\n",
      "auto encoder: 88.05 ms\n",
      "deep ant: 437.56 ms\n",
      "histogram: --\n",
      "clustering: --\n",
      "TOTAL: 525.83 ms \n",
      "\n",
      "Iniciando an√°lise da amostra\n",
      "==================================================\n",
      "auto encoder: 117.24 ms\n",
      "deep ant: 290.53 ms\n",
      "histogram: --\n",
      "clustering: --\n",
      "TOTAL: 407.98 ms \n",
      "\n",
      "Iniciando an√°lise da amostra\n",
      "==================================================\n",
      "auto encoder: 48.30 ms\n",
      "deep ant: 323.04 ms\n",
      "histogram: --\n",
      "clustering: --\n",
      "TOTAL: 371.53 ms \n",
      "\n",
      "Iniciando an√°lise da amostra\n",
      "==================================================\n",
      "auto encoder: 54.65 ms\n",
      "deep ant: 312.01 ms\n",
      "histogram: --\n",
      "clustering: --\n",
      "TOTAL: 366.86 ms \n",
      "\n",
      "Iniciando an√°lise da amostra\n",
      "==================================================\n",
      "auto encoder: 83.67 ms\n",
      "deep ant: 382.26 ms\n",
      "histogram: --\n",
      "clustering: --\n",
      "TOTAL: 466.13 ms \n",
      "\n",
      "Iniciando an√°lise da amostra\n",
      "==================================================\n",
      "auto encoder: 79.47 ms\n",
      "deep ant: 389.86 ms\n",
      "histogram: 52.64 ms\n",
      "clustering: 418.56 ms\n",
      "TOTAL: 941.11 ms \n",
      "\n",
      "Iniciando an√°lise da amostra\n",
      "==================================================\n",
      "auto encoder: 45.99 ms\n",
      "deep ant: 282.15 ms\n",
      "histogram: 42.65 ms\n",
      "clustering: 445.50 ms\n",
      "TOTAL: 816.65 ms \n",
      "\n",
      "Iniciando an√°lise da amostra\n",
      "==================================================\n",
      "auto encoder: 53.30 ms\n",
      "deep ant: 366.37 ms\n",
      "histogram: 53.70 ms\n",
      "clustering: 439.86 ms\n",
      "TOTAL: 913.76 ms \n",
      "\n",
      "15 of 15 samples analyzed!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import time\n",
    "# record_array = compare_test.record\n",
    "record_array = [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1]\n",
    "save_path = abs_path + \"/data/wavelet_old\"\n",
    "cw = CompressWavelet(save_path, record_array, save_mode=\"ALL\")\n",
    "\n",
    "start_time_wvl = time.time()\n",
    "    \n",
    "compare_test = CompareData(data, dt, cw, slice_size=fs)\n",
    "    \n",
    "spend_time_wvl = time.time() - start_time_wvl\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of samples: 6\n",
      "0 of 6 samples analyzed...\n",
      "sample = 8\n",
      "sample = 16\n",
      "sample = 24\n",
      "sample = 32\n",
      "sample = 40\n",
      "sample = 48\n",
      "6 of 6 samples analyzed!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "#Load from file\n",
    "rec_data = cw.decode_from_file()\n",
    "rec_data.shape\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(60000, 4)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(data, rec_data)\n",
    "mae= mean_absolute_error(data, rec_data)\n",
    "print(\"Avalia√ß√£o do sinal reconstru√≠do:\")\n",
    "print(f\"MSE: {mse}, MAE: {mae}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Avalia√ß√£o do sinal reconstru√≠do:\n",
      "MSE: 0.023251261166575957, MAE: 0.07080130221630083\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}